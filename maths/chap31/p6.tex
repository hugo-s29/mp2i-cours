\part{Variance}

Dans ce paragrape, toutes les variables aléatoires sont à valeurs réelles.

\begin{defn}
	Soit $X : \Omega \to \R$ une variable aléatoire. La \underline{variance}\index{variance (variable aléatoire)} de $X$ est \[
		V(X) = E\left( \big(X - E(X)\big)^2 \right)
	.\]
\end{defn}

\begin{prop}
	Avec les notations précédentes, \[
		V(X) \ge 0
	.\]
\end{prop}

\begin{prv}
	On pose $\mu = E(X)$.
	\[
		V(X) = \sum_{x \in X(\Omega)}\underbrace{(x-\mu)^2\: P(X = x)}_{\ge 0} \ge 0
	.\]
\end{prv}

\begin{defn}
	L'\underline{écart-type}\index{écart-type (variable aléatoire)} de $X$ est \[
		\sigma_X = \sqrt{V(X)}
	.\]
\end{defn}

\begin{defn}
	On dit que $X$ vérifie \underline{presque sûrement} une propriété si la probabilité que $X$ vérifie cette propriété vaut 1.\index{presque sûrement (variables aléatoires)}
\end{defn}

\begin{prop}
	\[
		V(X) = 0 \iff X \text{ est presque sûrement constante}.
	.\] \qed
\end{prop}

\begin{prop}[K\oe nig-Huygens]
	\[
		V(X) = E(X^2) - E(X)^2
	.\]
\end{prop}

\begin{prv}
	On pose $\mu = E(X)$
	\begin{align*}
		V(X) &= E\big((X-\mu)^2\big)\\
		&= E(X^2 - 2\mu X + \mu^2) \\
		&= E(X^2) - 2\mu E(X) + \mu^2 E(1) \\
		&= E(X^2) - 2\mu^2 + \mu^2 \\
		&= E(X^2) - \mu^2 \\
	\end{align*}
\end{prv}

\begin{exm}
	\begin{enumerate}
		\item Avec $X \sim \mathcal{B}(p)$, on a $X^2 \sim \mathcal{B}(p)$ d'où \[
				V(X) = p - p^2 = p (1-p) = pq \le \frac{1}{4} \text{ avec } q = 1-p
			\]
		\item Avec $X \sim \mathcal{B}(n,p)$.
			\begin{align*}
				E(X^2) &= \sum_{k=0}^n k^2 {n\choose k} p^k q^{n-k}\\
				&= \cdots\cdots\cdots \\
			\end{align*}
			En faisant le calcul, on trouve $V(X) = n p q$.
	\end{enumerate}
\end{exm}

\begin{thm}
	Soit $X,Y : \Omega \to \R$. \[
		V(X+Y) = V(X) + V(Y) + 2\Cov(X,Y)
	\] où $\Cov(X,Y) = E(XY) - E(X)\,E(Y)$ est la \underline{covariance}\index{covariance (variables aléatoires)} de $X$ et $Y$.
\end{thm}

\begin{prv}
	\begin{align*}
		E\big((X+Y)^2\big) &= E(X^2 + Y^2 + 2XY) \\
		&= E(X^2) + E(Y^2) + 2E(XY) \\
	\end{align*}
	et
	\begin{align*}
		\big(E(X+Y)\big)^2 &= \big(E(X) + E(Y)\big)^2 \\
		&= E(X)^2 + E(Y)^2 + 2E(X)E(Y). \\
	\end{align*}
	D'où \[
		V(X+Y) = V(X) + V(Y) + 2\Cov(X,Y)
	.\]
\end{prv}

\begin{prop}
	Si $X \indep Y$, alors $\Cov(X,Y) = 0$. D'où \[
		V(X+Y) = V(X) + V(Y)
	.\]
\end{prop}

\begin{prv}
	\begin{align*}
		E(XY) &= \sum_{\substack{x \in X(\Omega)\\y \in Y(\Omega)}} xy\, P(X = x,Y=y) \\
		&= \sum_{x \in X(\Omega)}\sum_{y \in Y(\Omega)} xy P(X=x)P(Y=y) \\
		&= \sum_{x \in X(\Omega)} x\,P(X=x)\;\sum_{y \in Y(\Omega)}y\,P(Y=y) \\
		&= E(X) E(Y) \\
	\end{align*}
\end{prv}

\begin{prop}
	Soit $(X_i)_{1\le i\le n}$ des variabls aléatoires définies sur le même espace probabilisé $(\Omega, P)$. Alors
	\begin{align*}
		V\left( \sum_{i=1}^n X_i \right) &= \sum_{1\le i,j\le n} \Cov(X_i, X_j)\\
		&= \sum_{i=1}^n V(X_i) + 2 \sum_{1\le i<j\le n}\Cov(X_i, X_j) \\
	\end{align*}
	\qed
\end{prop}

\begin{crlr}
	Avec les notations précédentes, si les $X_i$ sont deux à deux non \underline{corrélés}\index{correlation (variables aléatoires)} (i.e. $\Cov(X_i,X_j) = 0$ pour $i \neq j$), alors \[
		V\left( \sum_{i=1}^n X_i \right) = \sum_{i=1}^n V(X_i)
	.\]\qed
\end{crlr}

\begin{crlr}
	Avec les notations précédentes, si les $X_i$ sont indépendantes deux à deux, alors \[
		V\left( \sum_{i=1}^n X_i \right)  = \sum_{i=1}^n V(X_i)
	.\]\qed
\end{crlr}

\begin{crlr}
	Soit $X \sim \mathcal{B}(n,p)$. Alors, \[
		V(X) = np(1-p)
	.\]
\end{crlr}

\begin{prv}
	On pose $X \sim \sum_{i=1}^n X_i$ où les $(X_i)$ sont mutuellement indépendants et $\forall i$, $X_i \sim \mathcal{B}(p)$.

	\begin{align*}
		V(X) &= V\left( \sum_{i=1}^n X_i \right)\\
		&= \sum_{i=1}^n V(X_i) \\
		&= \sum_{i=1}^n p(1-p) \\
		&= np(1-p) \\
	\end{align*}
\end{prv}

\begin{prop}[transfert] Soient $X_1, \ldots, X_n$ des variables aléatoires à valeurs réelles toutes définies sur un même espace probabilisé $(\Omega,P)$ et $f : \R^n \longrightarrow \R$ \[
	E\big(f(X_1, \ldots, X_n)\big) = \sum_{x_1 \in X_1(\Omega)}\cdots\sum_{x_n \in X_n(\Omega)} f(x_1, \ldots, x_n)P(X_1 = x_1, \ldots, X_n = x_n)
.\]
\end{prop}

\begin{prv}
	\begin{align*}
		E\big(f(X_1, \ldots, X_n)\big) &= \sum_{\omega \in \Omega} f\big(X_1(\omega),\ldots,X_n(\omega)\big)\:P\big(\{\omega\}\big)\\
		&= \sum_{x_1 \in X_1(\Omega)} \cdots \sum_{x_n \in X_n(\Omega)} \sum_{\substack{\omega \in \Omega\\\forall i,\,X_i(\omega) = x_i}} f\big(X_1(\omega),\ldots,X_n(\omega)\big)\:P\big(\{\omega\}\big) \\
		&= \sum_{x_1 \in X_1(\Omega)}\cdots\sum_{x_n \in X_n(\Omega)} f(x_1,\ldots,x_n) \sum_{\substack{\omega \in \Omega\\\forall i,\,X_i(\omega) = x_i}} P\big(\{\omega\}\big) \\
		&= \sum_{x_1 \in X_1(\Omega)}\cdots \sum_{x_n \in X_n} f(x_1, \ldots, x_n) P(X_1 = x_1, \ldots, X_n = x_n) \\
	\end{align*}
\end{prv}


